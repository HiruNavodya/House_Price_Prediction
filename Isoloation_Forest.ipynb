{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab99f131",
   "metadata": {},
   "source": [
    "# Clustering Approach - 02 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bb9793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ydata_profiling import ProfileReport\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from collections import Counter\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ba9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data (3).csv', index_col='date')\n",
    "def Basic_Preprocessing(df):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index = df.index.date  \n",
    "\n",
    "    \n",
    "    df.drop(columns=['country','street'],inplace=True)\n",
    "    df = df[df['price'] != 0]\n",
    "    df['yr_renovated'] = df['yr_renovated'].apply(lambda x: 1 if x!=0 else 0)\n",
    "    df['waterfront'] =  df['waterfront'].apply(lambda x: 1 if x!=0 else 0)\n",
    "    df['yr_built'] = df['yr_built'].apply(lambda x: 1 if x > df['yr_built'].median() else 0)\n",
    "    df['sqft_total'] = df['sqft_basement'] + df['sqft_above']\n",
    "    df.drop(columns=['sqft_basement','sqft_above'],inplace=True)\n",
    "    #df.drop(columns=['statezip'],inplace=True)\n",
    "    df['statezip'] = df['statezip'].apply(lambda x: int(str(x).split()[1]))\n",
    "    df['month'] = pd.to_datetime(df.index).month\n",
    "    df['date'] = pd.to_datetime(df.index).day\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df \n",
    "\n",
    "df = Basic_Preprocessing(data)\n",
    "\n",
    "X = df.drop(columns=['price'])\n",
    "Y= df['price']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fd9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_cats(data, col, Y):\n",
    "    df = pd.DataFrame(data[col])\n",
    "    df['price'] = Y\n",
    "    dummy = pd.get_dummies(df[col], prefix=f'${col}$', dtype=int)\n",
    "    df = pd.concat([df, dummy], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    # Train a Random Forest model\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(df.drop('price', axis=1), Y)\n",
    "\n",
    "    # Get feature importance scores\n",
    "    feature_importances = rf.feature_importances_\n",
    "\n",
    "    # Sort features based on their importance scores\n",
    "    selected_features_indices = np.argsort(feature_importances)[::-1]\n",
    "    selected_features = df.columns[selected_features_indices][:10]\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523addb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd066f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76cfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca576d20",
   "metadata": {},
   "source": [
    "## Spliting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfec4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9bafce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ##########  Label encoding \\nfrom sklearn.preprocessing import OrdinalEncoder\\nordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\\nordinal_encoder.fit(X_train[['city']])\\n\\n# Transform both training and test sets\\nX_train['city'] = ordinal_encoder.transform(X_train[['city']])\\nX_test['city'] = ordinal_encoder.transform(X_test[['city']])\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ##########  Label encoding \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ordinal_encoder.fit(X_train[['city']])\n",
    "\n",
    "# Transform both training and test sets\n",
    "X_train['city'] = ordinal_encoder.transform(X_train[['city']])\n",
    "X_test['city'] = ordinal_encoder.transform(X_test[['city']])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d807b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########  One hot encoding \n",
    "combined_df = pd.concat([X_train, X_test])\n",
    "dummy_cols = ['city']\n",
    "combined_dummy_df = pd.get_dummies(combined_df[dummy_cols], drop_first=True)\n",
    "X_train_dummy = combined_dummy_df.iloc[:len(X_train)]\n",
    "X_test_dummy = combined_dummy_df.iloc[len(X_train):]\n",
    "X_train_dummy = X_train_dummy.astype(int)\n",
    "X_test_dummy = X_test_dummy.astype(int)\n",
    "X_train = X_train.drop(columns=dummy_cols)\n",
    "X_test = X_test.drop(columns=dummy_cols)\n",
    "X_train = pd.concat([X_train, X_train_dummy], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_dummy], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5fc9d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#############  Frequency Encoding \\ncity_frequency = X_train['city'].value_counts(normalize=True)\\n\\n# Map the frequency values to the corresponding categories in both training and testing datasets\\nX_train['city'] = X_train['city'].map(city_frequency)\\nX_test['city'] = X_test['city'].map(city_frequency)\\n\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#############  Frequency Encoding \n",
    "city_frequency = X_train['city'].value_counts(normalize=True)\n",
    "\n",
    "# Map the frequency values to the corresponding categories in both training and testing datasets\n",
    "X_train['city'] = X_train['city'].map(city_frequency)\n",
    "X_test['city'] = X_test['city'].map(city_frequency)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "388fdd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Merge 'price' from y_train with 'city' in X_train\\nmean_target_encoding = y_train.groupby(X_train['city']).mean()\\n\\n# Map the mean target encoding back to the original DataFrame\\nX_train['city'] = X_train['city'].map(mean_target_encoding)\\nX_test['city'] = X_test['city'].map(mean_target_encoding)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Merge 'price' from y_train with 'city' in X_train\n",
    "mean_target_encoding = y_train.groupby(X_train['city']).mean()\n",
    "\n",
    "# Map the mean target encoding back to the original DataFrame\n",
    "X_train['city'] = X_train['city'].map(mean_target_encoding)\n",
    "X_test['city'] = X_test['city'].map(mean_target_encoding)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb672a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encoding for 10 most frequent cats \n",
    "top_10_cities = X_train['city'].value_counts().head(10).index.tolist()\n",
    "\n",
    "# Filter the DataFrame to include only the top 10 cities\n",
    "X_train_top_10 = X_train[X_train['city'].isin(top_10_cities)]\n",
    "X_test_top_10 = X_test[X_test['city'].isin(top_10_cities)]\n",
    "\n",
    "# Perform one-hot encoding for the top 10 cities\n",
    "dummy_cols_top_10 = ['city']\n",
    "combined_dummy_df_top_10 = pd.get_dummies(X_train_top_10[dummy_cols_top_10], drop_first=True)\n",
    "X_train_dummy_top_10 = combined_dummy_df_top_10.astype(int)\n",
    "\n",
    "# Apply the same encoding to the test set\n",
    "X_test_dummy_top_10 = pd.get_dummies(X_test_top_10[dummy_cols_top_10], drop_first=True).astype(int)\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "X_train = pd.concat([X_train_top_10.drop(columns=dummy_cols_top_10), X_train_dummy_top_10], axis=1)\n",
    "X_test = pd.concat([X_test_top_10.drop(columns=dummy_cols_top_10), X_test_dummy_top_10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0791da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28418bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ded466",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  by adjusting contamination we can make our model more sensitive to outliers \n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(contamination=0.2)  \n",
    "clf.fit(X_train)\n",
    "y_pred = clf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4f0cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5345309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2186"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a3c871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cluster_lables'] = y_pred\n",
    "\n",
    "X_train_1 = X_train[X_train['cluster_lables']==-1]\n",
    "X_train_2 = X_train[X_train['cluster_lables']==1]\n",
    "\n",
    "indexes_1 = X_train_1.index\n",
    "indexes_2 = X_train_2.index\n",
    "\n",
    "\n",
    "y_train_1 = y_train.loc[indexes_1]\n",
    "y_train_2 = y_train.loc[indexes_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4c1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90160f1b",
   "metadata": {},
   "source": [
    "# Best model for cluster 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c407e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cluster_1 , x_test_cluster_1 , y_train_cluster_1 , y_test_cluster_1 = train_test_split(\n",
    "                                        X_train_1.drop(columns=['date','month']),y_train_1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c537d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
       "       'waterfront', 'view', 'condition', 'yr_built', 'yr_renovated',\n",
       "       'statezip', 'sqft_total', 'city_Bellevue', 'city_Federal Way',\n",
       "       'city_Issaquah', 'city_Kent', 'city_Kirkland', 'city_Redmond',\n",
       "       'city_Renton', 'city_Sammamish', 'city_Seattle', 'cluster_lables'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cluster_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b5c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_transform = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "       'view', 'condition', 'sqft_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee3ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Min Max scaling for  votes :\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform on training data\n",
    "x_train_cluster_1 = x_train_cluster_1.copy()  # Create a copy to avoid modifying the original data\n",
    "x_train_cluster_1[vars_to_transform] = scaler.fit_transform(x_train_cluster_1[vars_to_transform])\n",
    "\n",
    "# Transform test data using the scaler fitted on training data\n",
    "x_test_cluster_1 = x_test_cluster_1.copy()  # Create a copy to avoid modifying the original data\n",
    "x_test_cluster_1[vars_to_transform] = scaler.transform(x_test_cluster_1[vars_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738a6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cluster_1 = np.log1p(y_train_cluster_1)\n",
    "y_test_cluster_1 = np.log1p(y_test_cluster_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b0e2d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.842688626342937\n",
      "Adjusted R-squared (Test): 0.9181144250846109\n",
      "RMSE (Training): 0.2674955747422373\n",
      "RMSE (Testing): 0.16410031393040433\n"
     ]
    }
   ],
   "source": [
    "gb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(estimator=gb_reg, param_grid=gb_params,\n",
    "                           cv=5, scoring='neg_mean_squared_error',\n",
    "                           n_jobs=-1)\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Get the best model\n",
    "best_gb_model_1 = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "###########################################################################################################\n",
    "##########   calculate  the adj R squred value   for training \n",
    "from sklearn.metrics import r2_score\n",
    "best_gb_model_1.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "y_train_pred = best_gb_model_1.predict(x_train_cluster_1)\n",
    "r_squared = r2_score(y_train_cluster_1, y_train_pred)\n",
    "n = len(y_train_cluster_1)\n",
    "p = x_train_cluster_1.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########y_test_pred = best_gb_model_1.predict(x_test_cluster_1)\n",
    "best_gb_model_1.fit(x_test_cluster_1, y_test_cluster_1)\n",
    "y_test_pred = best_gb_model_1.predict(x_test_cluster_1)\n",
    "r_squared_test = r2_score(y_test_cluster_1, y_test_pred)\n",
    "n_test = len(y_test_cluster_1)\n",
    "p_test = x_test_cluster_1.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "######################################################################################\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_1, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_1, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5c4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c7150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ab729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9e92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a21180b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.8179953002278694\n",
      "Adjusted R-squared (Test): 0.6022365850777054\n",
      "RMSE (Training): 0.2877251607454853\n",
      "RMSE (Testing): 0.3616746987295675\n"
     ]
    }
   ],
   "source": [
    "#################################   Random Forest   ###########################################\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "# Grid search\n",
    "grid_search_rf = GridSearchCV(estimator=rf_reg, param_grid=rf_params,\n",
    "                              cv=5, scoring='neg_mean_squared_error',\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_rf.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model_1 = grid_search_rf.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#################   calculate  the adj R squred value  ####################### #\n",
    "best_rf_model_1.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "y_train_pred = best_rf_model_1.predict(x_train_cluster_1)\n",
    "r_squared = r2_score(y_train_cluster_1, y_train_pred)\n",
    "n = len(y_train_cluster_1)\n",
    "p = x_train_cluster_1.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_rf_model_1.predict(x_test_cluster_1)\n",
    "r_squared_test = r2_score(y_test_cluster_1, y_test_pred)\n",
    "n_test = len(y_test_cluster_1)\n",
    "p_test = x_test_cluster_1.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_1, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_1, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32193a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca90fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e08804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ccf673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.6714440087342011\n",
      "Adjusted R-squared (Test): 0.5347660861893009\n",
      "RMSE (Training): 0.3506555205771757\n",
      "RMSE (Testing): 0.3746423075328432\n"
     ]
    }
   ],
   "source": [
    "######################################  Ada Boost   ###############################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create AdaBoostRegressor\n",
    "ada_reg = AdaBoostRegressor()\n",
    "\n",
    "# Grid search for AdaBoost\n",
    "grid_search_ada = GridSearchCV(estimator=ada_reg, param_grid=ada_params,\n",
    "                                cv=5, scoring='neg_mean_squared_error',\n",
    "                                n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV for AdaBoost\n",
    "grid_search_ada.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Get the best AdaBoost model\n",
    "best_ada_model_1 = grid_search_ada.best_estimator_\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "##########################################################################################################\n",
    "#################   calculate  the adj R squred value  ########################\n",
    "best_ada_model_1.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "y_train_pred = best_ada_model_1.predict(x_train_cluster_1)\n",
    "r_squared = r2_score(y_train_cluster_1, y_train_pred)\n",
    "n = len(y_train_cluster_1)\n",
    "p = x_train_cluster_1.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_ada_model_1.predict(x_test_cluster_1)\n",
    "r_squared_test = r2_score(y_test_cluster_1, y_test_pred)\n",
    "n_test = len(y_test_cluster_1)\n",
    "p_test = x_test_cluster_1.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_1, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_1, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776710a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12317044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edb63e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.4415472750208054\n",
      "Adjusted R-squared (Test): 0.36583633269163185\n",
      "RMSE (Training): 0.503999084174611\n",
      "RMSE (Testing): 0.45667410777513606\n"
     ]
    }
   ],
   "source": [
    "#######################  ElasticNet ###############################\n",
    "elastic_net_params = {\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Create ElasticNet regressor\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Grid search\n",
    "grid_search_elastic_net = GridSearchCV(estimator=elastic_net, param_grid=elastic_net_params,\n",
    "                                       cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_elastic_net.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Get the best model\n",
    "best_elastic_net_model_1 = grid_search_elastic_net.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "#################   calculate  the adj R squred value  ########################\n",
    "best_elastic_net_model_1.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "y_train_pred =best_elastic_net_model_1.predict(x_train_cluster_1)\n",
    "r_squared = r2_score(y_train_cluster_1, y_train_pred)\n",
    "n = len(y_train_cluster_1)\n",
    "p = x_train_cluster_1.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_elastic_net_model_1.predict(x_test_cluster_1)\n",
    "r_squared_test = r2_score(y_test_cluster_1, y_test_pred)\n",
    "n_test = len(y_test_cluster_1)\n",
    "p_test = x_test_cluster_1.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_1, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_1, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbdda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d245ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc3c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37be3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "881eba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.6692298956861347\n",
      "Adjusted R-squared (Test): 0.580166826973322\n",
      "RMSE (Training): 0.38788203476359057\n",
      "RMSE (Testing): 0.37157294642370975\n"
     ]
    }
   ],
   "source": [
    "####################  Ridge #####################\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "# Create Ridge regressor\n",
    "ridge_reg = Ridge()\n",
    "\n",
    "# Grid search\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge_reg, param_grid=ridge_params,\n",
    "                                 cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_ridge.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Get the best model\n",
    "best_ridge_model_1 = grid_search_ridge.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "#################   calculate  the adj R squred value  ########################\n",
    "best_ridge_model_1.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "y_train_pred =best_ridge_model_1.predict(x_train_cluster_1)\n",
    "r_squared = r2_score(y_train_cluster_1, y_train_pred)\n",
    "n = len(y_train_cluster_1)\n",
    "p = x_train_cluster_1.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_ridge_model_1.predict(x_test_cluster_1)\n",
    "r_squared_test = r2_score(y_test_cluster_1, y_test_pred)\n",
    "n_test = len(y_test_cluster_1)\n",
    "p_test = x_test_cluster_1.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_1, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_1, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c587785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2fefae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31190568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f3d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccd60902",
   "metadata": {},
   "source": [
    "# Best model for cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "593f3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cluster_2 , x_test_cluster_2 , y_train_cluster_2 , y_test_cluster_2 = train_test_split(X_train_2,\n",
    "                                                                                    y_train_2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ae90aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_transform = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "       'view', 'condition', 'sqft_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "677bee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Min Max scaling for  votes :\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform on training data\n",
    "x_train_cluster_2 = x_train_cluster_2.copy()  # Create a copy to avoid modifying the original data\n",
    "x_train_cluster_2[vars_to_transform] = scaler.fit_transform(x_train_cluster_2[vars_to_transform])\n",
    "\n",
    "# Transform test data using the scaler fitted on training data\n",
    "x_test_cluster_2 = x_test_cluster_2.copy()  # Create a copy to avoid modifying the original data\n",
    "x_test_cluster_2[vars_to_transform] = scaler.transform(x_test_cluster_2[vars_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49baa6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cluster_2 = np.log1p(y_train_cluster_2)\n",
    "y_test_cluster_2 = np.log1p(y_test_cluster_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef84b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.8963865676383401\n",
      "Adjusted R-squared (Test): 0.7440674714034403\n",
      "RMSE (Training): 0.14485327825114525\n",
      "RMSE (Testing): 0.22414382090609436\n"
     ]
    }
   ],
   "source": [
    "gb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(estimator=gb_reg, param_grid=gb_params,\n",
    "                           cv=5, scoring='neg_mean_squared_error',\n",
    "                           n_jobs=-1)\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Get the best model\n",
    "best_gb_model_2 = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "#########################################################################################################\n",
    "##########   calculate  the adj R squred value   for training \n",
    "from sklearn.metrics import r2_score\n",
    "best_gb_model_2.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "y_train_pred = best_gb_model_2.predict(x_train_cluster_2)\n",
    "r_squared = r2_score(y_train_cluster_2, y_train_pred)\n",
    "n = len(y_train_cluster_2)\n",
    "p = x_train_cluster_2.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_gb_model_2.predict(x_test_cluster_2)\n",
    "r_squared_test = r2_score(y_test_cluster_2, y_test_pred)\n",
    "n_test = len(y_test_cluster_2)\n",
    "p_test = x_test_cluster_2.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "\n",
    "#######################################   RMSE \n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_2, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_2, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175feee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011546e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bba462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f6f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a634cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################   Random Forest   ###########################################\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "# Grid search\n",
    "grid_search_rf = GridSearchCV(estimator=rf_reg, param_grid=rf_params,\n",
    "                              cv=5, scoring='neg_mean_squared_error',\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_rf.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model_2 = grid_search_rf.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#################   calculate  the adj R squred value  ####################### #\n",
    "best_rf_model_2.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "y_train_pred = best_rf_model_2.predict(x_train_cluster_2)\n",
    "r_squared = r2_score(y_train_cluster_2, y_train_pred)\n",
    "n = len(y_train_cluster_2)\n",
    "p = x_train_cluster_2.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_rf_model_2.predict(x_test_cluster_2)\n",
    "r_squared_test = r2_score(y_test_cluster_2, y_test_pred)\n",
    "n_test = len(y_test_cluster_2)\n",
    "p_test = x_test_cluster_2.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "#######################################   RMSE \n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_2, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_2, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a8143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e50744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf40110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3da27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8135b354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################  Ada Boost   ###############################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create AdaBoostRegressor\n",
    "ada_reg = AdaBoostRegressor()\n",
    "\n",
    "# Grid search for AdaBoost\n",
    "grid_search_ada = GridSearchCV(estimator=ada_reg, param_grid=ada_params,\n",
    "                                cv=5, scoring='neg_mean_squared_error',\n",
    "                                n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV for AdaBoost\n",
    "grid_search_ada.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Get the best AdaBoost model\n",
    "best_ada_model_2 = grid_search_ada.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "#################   calculate  the adj R squred value  ########################\n",
    "best_ada_model_2.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "y_train_pred = best_ada_model_2.predict(x_train_cluster_2)\n",
    "r_squared = r2_score(y_train_cluster_2, y_train_pred)\n",
    "n = len(y_train_cluster_1)\n",
    "p = x_train_cluster_2.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_ada_model_2.predict(x_test_cluster_2)\n",
    "r_squared_test = r2_score(y_test_cluster_2, y_test_pred)\n",
    "n_test = len(y_test_cluster_2)\n",
    "p_test = x_test_cluster_2.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "## RMSE \n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_2, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_2, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2487c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70206d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9864ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.2532517318624038\n",
      "Adjusted R-squared (Test): 0.23361519152328747\n",
      "RMSE (Training): 0.3888726593757005\n",
      "RMSE (Testing): 0.3878711438256147\n"
     ]
    }
   ],
   "source": [
    "#######################  ElasticNet ###############################\n",
    "elastic_net_params = {\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Create ElasticNet regressor\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Grid search\n",
    "grid_search_elastic_net = GridSearchCV(estimator=elastic_net, param_grid=elastic_net_params,\n",
    "                                       cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_elastic_net.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Get the best model\n",
    "best_elastic_net_model_2 = grid_search_elastic_net.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#################   calculate  the adj R squred value  ########################\n",
    "best_elastic_net_model_2.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "y_train_pred =best_elastic_net_model_2.predict(x_train_cluster_2)\n",
    "r_squared = r2_score(y_train_cluster_2, y_train_pred)\n",
    "n = len(y_train_cluster_2)\n",
    "p = x_train_cluster_2.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_elastic_net_model_2.predict(x_test_cluster_2)\n",
    "r_squared_test = r2_score(y_test_cluster_2, y_test_pred)\n",
    "n_test = len(y_test_cluster_2)\n",
    "p_test = x_test_cluster_2.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "############  RMSE \n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_2, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_2, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa1c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268a605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd8965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26ca435a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.6448545471691687\n",
      "Adjusted R-squared (Test): 0.648988374946696\n",
      "RMSE (Training): 0.26817817272436\n",
      "RMSE (Testing): 0.26249726161083237\n"
     ]
    }
   ],
   "source": [
    "####################  Ridge #####################\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Create Ridge regressor\n",
    "ridge_reg = Ridge()\n",
    "\n",
    "# Grid search\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge_reg, param_grid=ridge_params,\n",
    "                                 cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_ridge.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Get the best model\n",
    "best_ridge_model_2 = grid_search_ridge.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "#################   calculate  the adj R squred value  ########################\n",
    "best_ridge_model_2.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "y_train_pred =best_ridge_model_2.predict(x_train_cluster_2)\n",
    "r_squared = r2_score(y_train_cluster_2, y_train_pred)\n",
    "n = len(y_train_cluster_2)\n",
    "p = x_train_cluster_2.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "\n",
    "#########   calculate  the adj R squred value   for testing ##########\n",
    "y_test_pred = best_ridge_model_2.predict(x_test_cluster_2)\n",
    "r_squared_test = r2_score(y_test_cluster_2, y_test_pred)\n",
    "n_test = len(y_test_cluster_2)\n",
    "p_test = x_test_cluster_2.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "############  RMSE \n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_cluster_2, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_cluster_2, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418804e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7a009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457fc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "568d8450",
   "metadata": {},
   "source": [
    "# Final Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c02cc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_test)\n",
    "labels = clf.predict(X_test)\n",
    "X_test['cluster_lables'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d532bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_1 = X_test[X_test['cluster_lables']==-1]\n",
    "X_test_1.drop(columns=['month','date'],inplace=True)\n",
    "X_test_2 =  X_test[X_test['cluster_lables']==1]\n",
    "\n",
    "# Get indices of cluster 1 and cluster 2 in X_test\n",
    "indexes_1 = X_test[X_test['cluster_lables'] == -1].index\n",
    "indexes_2 = X_test[X_test['cluster_lables'] == 1].index\n",
    "\n",
    "# Filter y_test based on the indices\n",
    "y_test_1 = y_test.loc[indexes_1]\n",
    "y_test_2 = y_test.loc[indexes_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bcb1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "################  Transformations \n",
    "\n",
    "### Min Max scaling for  votes :\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform on training data\n",
    "X_test_1 = X_test_1.copy()  # Create a copy to avoid modifying the original data\n",
    "X_test_1[vars_to_transform] = scaler.fit_transform(X_test_1[vars_to_transform])\n",
    "\n",
    "# Transform test data using the scaler fitted on training data\n",
    "X_test_2 = X_test_2.copy()  # Create a copy to avoid modifying the original data\n",
    "X_test_2[vars_to_transform] = scaler.transform(X_test_2[vars_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31dc9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1 = np.log1p(y_test_1)\n",
    "y_test_2 = np.log1p(y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66a65ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cluster_1 = best_gb_model_1\n",
    "best_model_cluster_2 = best_elastic_net_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d306605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_cluster_1 = best_model_cluster_1.predict(X_test_1)\n",
    "r_squared_cluster_1 = r2_score(y_test_1, y_test_pred_cluster_1)\n",
    "n_cluster_1 = len(y_test_1)\n",
    "p_cluster_1 = X_test_1.shape[1]\n",
    "adjusted_r_squared_cluster_1 = 1 - (1 - r_squared_cluster_1) * (n_cluster_1 - 1) / (n_cluster_1 - p_cluster_1 - 1)\n",
    "rmse_cluster_1 = mean_squared_error(y_test_1, y_test_pred_cluster_1, squared=False)\n",
    "\n",
    "y_test_pred_cluster_2 =  best_model_cluster_2.predict(X_test_2)\n",
    "r_squared_cluster_2 = r2_score(y_test_2, y_test_pred_cluster_2)\n",
    "n_cluster_2 = len(y_test_2)\n",
    "p_cluster_2 = X_test_2.shape[1]\n",
    "adjusted_r_squared_cluster_2 = 1 - (1 - r_squared_cluster_2) * (n_cluster_2 - 1) / (n_cluster_2 - p_cluster_2 - 1)\n",
    "rmse_cluster_2 = mean_squared_error(y_test_2, y_test_pred_cluster_2, squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d82fd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test R-squared: 0.34746128545556887\n",
      "Final Test MSE: 0.17965955304646353\n",
      "Final Test RMSE: 0.4238626582354991\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions for both clusters\n",
    "y_test_pred = np.concatenate((y_test_pred_cluster_1, y_test_pred_cluster_2))\n",
    "\n",
    "# Combine actual target values for both clusters\n",
    "y_test_combined = pd.concat([y_test_1, y_test_2])\n",
    "\n",
    "# Calculate R-squared for the combined test set\n",
    "r_squared_test_combined = r2_score(y_test_combined, y_test_pred)\n",
    "\n",
    "# Calculate mean squared error (MSE) for the combined test set\n",
    "mse_test_combined = mean_squared_error(y_test_combined, y_test_pred)\n",
    "\n",
    "# Calculate root mean squared error (RMSE) for the combined test set\n",
    "rmse_test_combined = np.sqrt(mse_test_combined)\n",
    "\n",
    "# Print the final test R-squared score, MSE, and RMSE\n",
    "print(\"Final Test R-squared:\", r_squared_test_combined)\n",
    "print(\"Final Test MSE:\", mse_test_combined)\n",
    "print(\"Final Test RMSE:\", rmse_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed346da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c33911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
