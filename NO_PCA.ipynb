{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977e66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ydata_profiling import ProfileReport\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from collections import Counter\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac4197",
   "metadata": {},
   "source": [
    "# Without PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb7a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data (3).csv', index_col='date')\n",
    "def Basic_Preprocessing(df):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index = df.index.date  \n",
    "\n",
    "    \n",
    "    df.drop(columns=['country','street'],inplace=True)\n",
    "    df = df[df['price'] != 0]\n",
    "    df['yr_renovated'] = df['yr_renovated'].apply(lambda x: 1 if x!=0 else 0)\n",
    "    df['waterfront'] =  df['waterfront'].apply(lambda x: 1 if x!=0 else 0)\n",
    "    df['yr_built'] = df['yr_built'].apply(lambda x: 1 if x > df['yr_built'].median() else 0)\n",
    "    df['sqft_total'] = df['sqft_basement'] + df['sqft_above']\n",
    "    df.drop(columns=['sqft_basement','sqft_above'],inplace=True)\n",
    "    #df.drop(columns=['statezip'],inplace=True)\n",
    "    df['statezip'] = df['statezip'].apply(lambda x: int(str(x).split()[1]))\n",
    "    df['month'] = pd.to_datetime(df.index).month\n",
    "    df['date'] = pd.to_datetime(df.index).day\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df \n",
    "\n",
    "df = Basic_Preprocessing(data)\n",
    "\n",
    "X = df.drop(columns=['price'])\n",
    "Y= df['price']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11aa6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1551d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########  One hot encoding \n",
    "combined_df = pd.concat([X_train, X_test])\n",
    "dummy_cols = ['city']\n",
    "combined_dummy_df = pd.get_dummies(combined_df[dummy_cols], drop_first=True)\n",
    "X_train_dummy = combined_dummy_df.iloc[:len(X_train)]\n",
    "X_test_dummy = combined_dummy_df.iloc[len(X_train):]\n",
    "X_train_dummy = X_train_dummy.astype(int)\n",
    "X_test_dummy = X_test_dummy.astype(int)\n",
    "X_train = X_train.drop(columns=dummy_cols)\n",
    "X_test = X_test.drop(columns=dummy_cols)\n",
    "X_train = pd.concat([X_train, X_train_dummy], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_dummy], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b14d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(contamination=0.1)  \n",
    "clf.fit(X_train)\n",
    "y_pred = clf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a618d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cluster_labels'] = y_pred\n",
    "X_train_filtered = X_train[X_train['cluster_labels'] == 1]\n",
    "indexes_1 = X_train_filtered.index\n",
    "y_train_filtered = y_train.loc[indexes_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d66531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_transform = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "       'view', 'condition', 'sqft_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba417f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform on training data\n",
    "X_train_filtered =X_train_filtered.copy()  # Create a copy to avoid modifying the original data\n",
    "X_train_filtered[vars_to_transform] = scaler.fit_transform(X_train_filtered[vars_to_transform])\n",
    "\n",
    "# Transform test data using the scaler fitted on training data\n",
    "X_test =X_test.copy()  # Create a copy to avoid modifying the original data\n",
    "X_test[vars_to_transform] = scaler.transform(X_test[vars_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c16fafeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_filtered = np.log1p(y_train_filtered)\n",
    "y_test = np.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240f65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ca4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f24709",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(estimator=gb_reg, param_grid=gb_params,\n",
    "                           cv=5, scoring='neg_mean_squared_error',\n",
    "                           n_jobs=-1)\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Get the best model\n",
    "best_gb_model_1 = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d778ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared: 0.8904968349520133\n",
      "Adjusted R-squared (Test): 0.9546201553881505\n",
      "RMSE (Training): 0.16509066164524708\n",
      "RMSE (Testing): 0.11162531190749074\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################################\n",
    "###########################################################################################################\n",
    "##########   calculate  the adj R squred value   for training \n",
    "from sklearn.metrics import r2_score\n",
    "best_gb_model_1.fit(X_train_filtered, y_train_filtered)\n",
    "y_train_pred = best_gb_model_1.predict(X_train_filtered)\n",
    "r_squared = r2_score(y_train_filtered, y_train_pred)\n",
    "n = len(y_train)\n",
    "p =X_train_filtered.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r_squared)\n",
    "\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########y_test_pred = best_gb_model_1.predict(x_test_cluster_1)\n",
    "best_gb_model_1.fit(X_test, y_test)\n",
    "y_test_pred = best_gb_model_1.predict(X_test)\n",
    "r_squared_test = r2_score(y_test, y_test_pred)\n",
    "n_test = len(y_test)\n",
    "p_test = X_test.shape[1]\n",
    "adjusted_r_squared_test = 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Test):\", adjusted_r_squared_test)\n",
    "\n",
    "######################################################################################\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_filtered, y_train_pred))\n",
    "print(\"RMSE (Training):\", rmse_train)\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(\"RMSE (Testing):\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b109675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8cb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27bed4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered.drop(columns=['cluster_labels'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4857c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec11eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared (Ridge - Training): 0.6907547146167841\n",
      "Adjusted R-squared (Ridge - Testing): 0.5988750995657606\n",
      "RMSE (Ridge - Training): 0.2772279098931435\n",
      "RMSE (Ridge - Testing): 0.33187229172917876\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Ridge regression\n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 1.0, 10.0],  # Regularization strength\n",
    "    # Add other parameters as needed\n",
    "}\n",
    "\n",
    "# Create Ridge regressor\n",
    "ridge_reg = Ridge()\n",
    "\n",
    "# Grid search\n",
    "ridge_grid_search = GridSearchCV(estimator=ridge_reg, param_grid=ridge_params,\n",
    "                                 cv=5, scoring='neg_mean_squared_error',\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "ridge_grid_search.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Get the best Ridge model\n",
    "best_ridge_model = ridge_grid_search.best_estimator_\n",
    "\n",
    "# Calculate adjusted R-squared for training set\n",
    "best_ridge_model.fit(X_train_filtered, y_train_filtered)\n",
    "y_train_pred_ridge = best_ridge_model.predict(X_train_filtered)\n",
    "r_squared_ridge = r2_score(y_train_filtered, y_train_pred_ridge)\n",
    "n_train = len(y_train_filtered)\n",
    "p_train = X_train_filtered.shape[1]\n",
    "adjusted_r_squared_ridge = 1 - (1 - r_squared_ridge) * (n_train - 1) / (n_train - p_train - 1)\n",
    "print(\"Adjusted R-squared (Ridge - Training):\", adjusted_r_squared_ridge)\n",
    "\n",
    "# Evaluate the Ridge model on the testing set\n",
    "y_test_pred_ridge = best_ridge_model.predict(X_test)\n",
    "r_squared_test_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "n_test = len(y_test)\n",
    "p_test = X_test.shape[1]\n",
    "adjusted_r_squared_test_ridge = 1 - (1 - r_squared_test_ridge) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Ridge - Testing):\", adjusted_r_squared_test_ridge)\n",
    "\n",
    "# Calculate RMSE for training set\n",
    "rmse_train_ridge = np.sqrt(mean_squared_error(y_train_filtered, y_train_pred_ridge))\n",
    "print(\"RMSE (Ridge - Training):\", rmse_train_ridge)\n",
    "\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test_ridge = np.sqrt(mean_squared_error(y_test, y_test_pred_ridge))\n",
    "print(\"RMSE (Ridge - Testing):\", rmse_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5aff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d4014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78a62c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared (Random Forest - Training): 0.6892265762078216\n",
      "Adjusted R-squared (Random Forest - Testing): 0.7533136400741973\n",
      "RMSE (Random Forest - Training): 0.27791202791819675\n",
      "RMSE (Random Forest - Testing): 0.2602577983223738\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "# Grid search\n",
    "rf_grid_search = GridSearchCV(estimator=rf_reg, param_grid=rf_params,\n",
    "                              cv=5, scoring='neg_mean_squared_error',\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "rf_grid_search.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Get the best Random Forest model\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "##########################################################################################################\n",
    "###########################################################################################################\n",
    "##########   calculate  the adj R squred value   for training \n",
    "from sklearn.metrics import r2_score\n",
    "best_rf_model.fit(X_train_filtered, y_train_filtered)\n",
    "y_train_pred_rf = best_rf_model.predict(X_train_filtered)\n",
    "r_squared_rf = r2_score(y_train_filtered, y_train_pred_rf)\n",
    "n_train = len(y_train_filtered)\n",
    "p_train = X_train_filtered.shape[1]\n",
    "adjusted_r_squared_rf = 1 - (1 - r_squared_rf) * (n_train - 1) / (n_train - p_train - 1)\n",
    "print(\"Adjusted R-squared (Random Forest - Training):\", adjusted_r_squared_rf)\n",
    "\n",
    "##########   calculate  the adj R squred value   for testing ##########y_test_pred = best_gb_model_1.predict(x_test_cluster_1)\n",
    "best_rf_model.fit(X_test, y_test)\n",
    "y_test_pred_rf = best_rf_model.predict(X_test)\n",
    "r_squared_test_rf = r2_score(y_test, y_test_pred_rf)\n",
    "n_test = len(y_test)\n",
    "p_test = X_test.shape[1]\n",
    "adjusted_r_squared_test_rf = 1 - (1 - r_squared_test_rf) * (n_test - 1) / (n_test - p_test - 1)\n",
    "print(\"Adjusted R-squared (Random Forest - Testing):\", adjusted_r_squared_test_rf)\n",
    "\n",
    "######################################################################################\n",
    "# Calculate RMSE for training set\n",
    "rmse_train_rf = np.sqrt(mean_squared_error(y_train_filtered, y_train_pred_rf))\n",
    "print(\"RMSE (Random Forest - Training):\", rmse_train_rf)\n",
    "\n",
    "# Calculate RMSE for testing set\n",
    "rmse_test_rf = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))\n",
    "print(\"RMSE (Random Forest - Testing):\", rmse_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9879dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6502b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448ded8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5dd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b609e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bb6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5ed26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ef656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
